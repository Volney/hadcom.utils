

#num.of.threads defines the number of thread used to read files into HDFS
# -Numbers greater then 1 will only help performance if your loading many files.
# -A input file will not be broken across threads
batch.files.thread.split=1

#put.reader defines which reader will be used to read the local file.
# -To be a valid value the class must extends AbstractLocalFileColumnReader
# -Here is a sample list of Readers
#    -  com.cloudera.sa.hcu.io.put.local.reader.DelimiterReader
#    -  com.cloudera.sa.hcu.io.put.local.reader.FlatFileReader
#    -  com.cloudera.sa.hcu.io.put.local.reader.VariableLengthDelimiterReader
#    -  com.cloudera.sa.hcu.io.put.local.reader.VariableLengthFlatFileReader
#    -  com.cloudera.sa.hcu.io.put.local.reader.FileNameAggregaterFileReader
put.reader=com.cloudera.sa.hcu.io.put.local.reader.DelimiterReader

#put.writer defines which writer will be used to write the column data to HDFS
# - To be a valid value the class must extend AbstractHdfsWriter
# - Here is a sample list of Writers
#    -  com.cloudera.sa.hcu.io.put.hdfs.writer.SequenceFileDelimiterWriter
#    -  com.cloudera.sa.hcu.io.put.hdfs.writer.AvroWriter
#    -  com.cloudera.sa.hcu.io.put.hdfs.writer.RcFileWriter
#    -  com.cloudera.sa.hcu.io.put.hdfs.writer.SequenceFileDelimiterWriter
put.writer=com.cloudera.sa.hcu.io.put.hdfs.writer.HBaseWriter

#Start Reader configuring examples <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<    

#Start example of configuring DelimiterReader
  reader.delimiter.regex=\\|
#End example of configuring DelimiterReader

#Start example of configuring FlatFileReader 
#  reader.field.lengths=2,3,4
#End example of configuring FlatFileReader

#Start example of configuring VariableLengthDelimiterReader
#  reader.row.type.index=2
#  reader.delimiter.regex=\|  
#End example of configuring VariableLengthDelimiterReader

#Start example of configuring VariableLengthFlatFileReader
#  reader.row.type.start.index=2
#  reader.row.type.length=3
#  reader.field.lengths.row.type.map=[{ "car", "2,3,4,5,2"},{ "pet", "3,3,3"}
#End example of configuring VariableLengthFlatFileReader

#Start example of configuring FileNameAggregaterFileReader
#  reader.aggregate.reader=com.cloudera.sa.hcu.io.put.local.reader.DelimiterReader
#  reader.delimiter.regex=\|
#End example of configuring FileNameAggregaterFileReader
  

#End Reader configuring examples >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

#Start Writer configuring examples <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#Start example of configuring SequenceFileDelimiterWriter
# writer.delimiter=|
# writer.compression.codec=snappy
#End example of configuring SequenceFileDelimiterWriter

#Start example of configuring RcFileWriter
#  writer.max.columns=3
#  writer.compression.codec=snappy
#End example of configuring RcFileWriter

#Start example of configuring AcroWriter
#  avro.writer.schema.json={ "name": "kfv", "type": "record", "fields": [{"name": "key", "type": "string"}, {"name": "field", "type": "string"}, {"name": "val", "type": "string"} ]};
#  writer.compression.codec=snappy
#End example of configuring AvroWriter

#Start example of configuring HBaseWriter
hbase.writer.table.user.key=%1$1s
hbase.writer.table.user.cf1.firstNm=%2$1s
hbase.writer.table.user.cf1.lastNm=%3$1s
hbase.writer.table.event.key=%4$1s-P-%1$1s
hbase.writer.table.event.cf1.user_id=%1$1s
# hbase.writer.table.event.key=%4$1s
hbase.writer.table.event.cf1.user_id_%1$1s=%2$1s_%3$1s
#End example of configuring HBaseWriter


#End Writer configuring examples >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
